{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4cebbf-1a19-4a85-9f7f-9e1209227f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lütfen bu linkten çalıştırabilirseniz harika olur , projeyi colab üzerinden yaptım.\n",
    "\n",
    "# Colab Linki\n",
    "# https://colab.research.google.com/drive/11IT_cXQ67DwkCGv2wXqwescwJJ6RncOV?usp=sharing\n",
    "# Çalışma zamanı > Çalışma zamanı türünü değiştir > v2-8 TPU seçeneğini seçin.\n",
    "# Ben projeyi Google Colab üzerinden yaptım ve bu modeli kullandım.\n",
    "\n",
    "\n",
    "# Kagglehub üzerinden veri setini indiriyoruz\n",
    "veri_seti_yolu = kagglehub.dataset_download(\"rrebirrth/animals-with-attributes-2\")\n",
    "\n",
    "\n",
    "# İndirilen veri setinin dosya sıraları\n",
    "ana_dizin = \"/root/.cache/kagglehub/datasets/rrebirrth/animals-with-attributes-2/versions/1/Animals_with_Attributes2/JPEGImages/\"\n",
    "\n",
    "# Sınıflandırılıcak hayvanlar\n",
    "istenen_hayvanlar = [\"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\",\n",
    "                     \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"]\n",
    "\n",
    "# Gereksiz sınıfları silelim\n",
    "print(\"Gereksiz hayvanlar siliniyor ...\")\n",
    "for klasor_yolu, alt_klasorler, _ in os.walk(ana_dizin, topdown=False):\n",
    "    for alt_klasor in alt_klasorler:\n",
    "        klasor_tam_yolu = os.path.join(klasor_yolu, alt_klasor)\n",
    "        if not any(hayvan in klasor_tam_yolu for hayvan in istenen_hayvanlar):\n",
    "            print(f\"{klasor_tam_yolu} klasörü siliniyor ...\")\n",
    "             # Alt klasördeki dosyaları silme işlemi\n",
    "            for dosya in os.listdir(klasor_tam_yolu):\n",
    "                dosya_tam_yolu = os.path.join(klasor_tam_yolu, dosya)\n",
    "                if os.path.isfile(dosya_tam_yolu):\n",
    "                    os.remove(dosya_tam_yolu)\n",
    "                elif os.path.isdir(dosya_tam_yolu):\n",
    "                    os.rmdir(dosya_tam_yolu)  # Alt klasörleri sil\n",
    "            os.rmdir(klasor_tam_yolu)  # Son olarak dizini sil\n",
    "\n",
    "\n",
    "# Fazlalık resimleri silelim , her sınıftan 650 tane olucak\n",
    "print(\"Her sınıftan yalnızca 650 resim bırakılıyor...] \\n\")\n",
    "for hayvan in istenen_hayvanlar:\n",
    "    klasor_yolu = os.path.join(ana_dizin, hayvan)\n",
    "\n",
    "    # Eğer klasör mevcutsa işlem yap\n",
    "    if os.path.exists(klasor_yolu):\n",
    "        dosyalar = os.listdir(klasor_yolu)\n",
    "        tam_yollar = sorted([os.path.join(klasor_yolu, dosya) for dosya in dosyalar])\n",
    "        print(f\"{hayvan} sınıfı için toplam resim sayısı: {len(dosyalar)}\")\n",
    "\n",
    "\n",
    "        # 650'den fazla resmi sil \n",
    "        for fazlalik_yol in tam_yollar[650:]:\n",
    "            print(f\"{fazlalik_yol} siliniyor...\")\n",
    "            os.remove(fazlalik_yol)  # Fazlalık resmi sil\n",
    "\n",
    "print(\"\\nVeri kümesi temizleme işlemi başarıyla tamamlandı!\")\n",
    "\n",
    "# Resimleri boyutlandırma ve normalize etme fonksiyonu\n",
    "def boyutayarlama_ve_normalizasyon(resim_yolu, size=(128, 128)):\n",
    "  img = cv2.imread(resim_yolu)  # Resmi okuma\n",
    "  img_boyut = cv2.resize(img, size)  # Resmi boyutlandırma\n",
    "  img_normalizasyon = img_boyut / 255.0  # Resmi normalize etme\n",
    "  return img_normalizasyon\n",
    "\n",
    "X = []  # Resimler\n",
    "y = []  # Etiketler\n",
    "import numpy as np\n",
    "for index,hayvan in enumerate(istenen_hayvanlar):\n",
    "  klasor_yolu = os.path.join(ana_dizin,hayvan)\n",
    "  for resim in os.listdir(klasor_yolu):\n",
    "    resim_yolu = os.path.join(klasor_yolu,resim)\n",
    "    resim_yolu = boyutayarlama_ve_normalizasyon(resim_yolu)# Resmi oku boyutlandır ve normalize et\n",
    "    X.append(resim_yolu) # Resim ekle\n",
    "    y.append(index)  # Etiket ekle\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Eğitim ve test verilerini ayrıyoruz\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y,random_state=42,test_size=0.3)\n",
    "\n",
    "# onehot encoding işlemi\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(Y_train, num_classes=len(istenen_hayvanlar))\n",
    "Y_test = to_categorical(Y_test, num_classes=len(istenen_hayvanlar))\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Veri artırma işlemleri\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "# Veri arttırma \n",
    "datagen.fit(X_train)\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# VGG16 modelini yükleyelim (pre-trained ImageNet ağırlıkları ile)\n",
    "vgg_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# VGG katmanlarını donduruyoruz artık weightler eğitilmeyecek\n",
    "for layer in vgg_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Son 4 katmanı eğitilebilir yapıyoruz\n",
    "for layer in vgg_base.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "# Kendi sınıflandırma katmanlarımızı ekleyelim\n",
    "x = vgg_base.output\n",
    "x = Flatten()(x)  # Düzleştirme işlemi\n",
    "x = Dense(256, activation=\"relu\")(x)  # Tam bağlı katman\n",
    "x = Dropout(0.5)(x)  # Dropout yaparak overfitting engelliyoruz\n",
    "output = Dense(len(istenen_hayvanlar), activation=\"softmax\")(x)  # Çıktı katmanı\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Yeni modeli oluşturma\n",
    "vgg_model = Model(inputs=vgg_base.input, outputs=output)\n",
    "\n",
    "# Modeli derleme\n",
    "vgg_model.compile(optimizer=Adam(learning_rate=0.0001),  # Metriklerimiz\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "epochs = 20  # Eğitim boyutu\n",
    "batch_size = 128 # Batch boyutu\n",
    "\n",
    "\n",
    "# Modeli eğitme işlemleri\n",
    "history = vgg_model.fit(datagen.flow(X_train, Y_train, batch_size=batch_size),# Test verileri\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_test, Y_test), # Doğrulama verisi\n",
    "                        steps_per_epoch=X_train.shape[0] // batch_size)\n",
    "\n",
    "\n",
    "# Loss ve acc değerlerini ekrana yazdırmaya yarar\n",
    "score = vgg_model.evaluate(X_test,Y_test,verbose = 0)\n",
    "print(\"Test Loss : \",score[0])\n",
    "print(\"Test Accuracy : \",score[1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'], label='Eğitim Doğruluk')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Doğruluk')\n",
    "plt.title(\"VGG16 Modeli Sonuçları\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Doğruluk')        # Görselleştirme işlemleri\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Eğitim Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.title(\"VGG16 Modeli Sonuçları\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')        # Görselleştirme işlemleri\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Test resimlerini manipüle etme ve kaydetme\n",
    "def manipulate_and_save_images(test_images):\n",
    "    manipulated_images = get_manipulated_images(test_images)  # Manipüle edilmiş görüntüler oluştur\n",
    "    manipulated_images = np.array(manipulated_images)  # NumPy dizisine dönüştür\n",
    "    return manipulated_images\n",
    "\n",
    "# Manipüle edilmiş resimleri oluşturma\n",
    "def get_manipulated_images(test_images):\n",
    "    manipulated_images = []\n",
    "    for image in test_images:\n",
    "        noise = np.random.normal(0, 0.1, image.shape)  # Gürültü ekleme\n",
    "        noisy_image = np.clip(image + noise, 0, 1)  # Değerleri 0-1 arasında sınırlama\n",
    "        manipulated_images.append(noisy_image)\n",
    "    return manipulated_images\n",
    "\n",
    "# Renk sabitliği uygulama\n",
    "def apply_white_balance_on_manipulated_images(manipulated_images):\n",
    "    wb_images = []\n",
    "    for image in manipulated_images:\n",
    "        wb_image = image  # Burada gerçek renk sabitliği fonksiyonu uygulanabilir\n",
    "        wb_images.append(wb_image)\n",
    "    return np.array(wb_images)\n",
    "\n",
    "# Modelin test seti ile değerlendirilmesi\n",
    "def evaluate_model(model, images, labels):\n",
    "    return model.evaluate(images, labels, verbose=0)[1]\n",
    "\n",
    "# Manipüle edilmiş ve renk sabitliği uygulanmış test setlerini değerlendirme\n",
    "manipulated_images = manipulate_and_save_images(X_test)  # Manipüle edilmiş test seti\n",
    "manipulated_scores = evaluate_model(vgg_model, manipulated_images, Y_test)  # Manipüle edilmiş test başarısı\n",
    "wb_images = apply_white_balance_on_manipulated_images(manipulated_images)  # Renk sabitliği uygulanmış test seti\n",
    "wb_scores = evaluate_model(vgg_model, wb_images, Y_test)  # Renk sabitliği uygulanmış test başarısı\n",
    "\n",
    "# Sonuçları karşılaştırma ve raporlama\n",
    "def compare_and_report_results(original_scores, manipulated_scores, wb_scores):\n",
    "    print(\"Orijinal Test Seti Başarı Oranı:\", original_scores)\n",
    "    print(\"Manipüle Edilmiş Test Seti Başarı Oranı:\", manipulated_scores)\n",
    "    print(\"Renk Sabitliği Uygulanmış Test Seti Başarı Oranı:\", wb_scores)\n",
    "\n",
    "    if wb_scores > manipulated_scores:\n",
    "        print(\"Renk sabitliği iyileştirme sağladı!\")\n",
    "    else:\n",
    "        print(\"Başarıda önemli bir fark bulunamadı.\")\n",
    "\n",
    "# Orijinal test seti başarısı\n",
    "original_scores = evaluate_model(vgg_model, X_test, Y_test)\n",
    "\n",
    "# Sonuçları karşılaştır ve raporla\n",
    "compare_and_report_results(original_scores, manipulated_scores, wb_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
